# ðŸ“Š Amazon Reviews Sentiment Analysis (NLP Project)

## ðŸ“Œ Problem Statement  
Customer reviews play a crucial role in shaping brand reputation and sales. Manually analyzing thousands of reviews is time-consuming and inconsistent.  
This project automates sentiment classification of Amazon reviews, helping businesses quickly identify **negative feedback** and improve customer satisfaction.  

---

## ðŸ“‚ Dataset  
- **Source:** [Amazon Fine Food Reviews (Kaggle)](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)  
- **Rows:** ~568,000 reviews  
- **Target Variable:** Sentiment (Positive / Negative)  
- **Features Used:**  
  - `Score` (1â€“5 stars, mapped to sentiment: 1â€“2 = negative, 3 = neutral (dropped), 4â€“5 = positive)  
  - `Text` (review content)  

---

## ðŸ›  Methodology  

### ðŸ”¹ Data Cleaning  
- Dropped neutral reviews for binary classification (positive vs negative).  
- Removed missing/blank values.  
- Cleaned text: lowercased, removed HTML, URLs, punctuation, and extra spaces.  

### ðŸ”¹ Feature Engineering  
- TF-IDF vectorization with parameters:  
  - `ngram_range=(1,2)` â†’ unigrams + bigrams  
  - `min_df=5`, `max_df=0.9` â†’ filter rare/common words  
  - `sublinear_tf=True` â†’ scale term frequency  
  - `stop_words="english"` â†’ remove stopwords  

### ðŸ”¹ Modeling  
- **Baseline:** Dummy Classifier (random guess based on class frequency).  
- **Multinomial Naive Bayes:** Classic text classifier.  
- **Logistic Regression:** Linear model with class balancing (best performer).  

### ðŸ”¹ Evaluation  
- Confusion Matrix  
- Accuracy, Precision, Recall, F1-score  
- Top positive/negative feature words  

---

## ðŸ“Š Results  


### ðŸ”¸ Confusion Matrix (Logistic Regression â€“ Test Set)  
![Model Performance Table](https://github.com/LakshayJakhar/amazon-reviews-sentiment-analysis/blob/7f2d472e8193ad5688ba15dd743f75ec13da1e92/images/Table.png)  

### ðŸ”¸ Model Insights  
- Logistic Regression achieved **95% accuracy** with **91% recall for negatives** â†’ best model.  
- Naive Bayes reached **93% accuracy** but weaker negative recall (**59%**).  
- Baseline only managed **74% accuracy** and failed on negatives.  

### ðŸ”¸ Top Features  
- **Positive words:** *delicious, excellent, perfect, tasty, amazing*  
- **Negative words:** *terrible, disappointed, waste, bland, awful*  

*(Feature importance bar chart can be added here)*  

---

## ðŸ“Œ Business Value  
- Flags **negative customer reviews** early â†’ businesses can act before churn or reputational damage.  
- Provides interpretable insights into **what words drive sentiment**.  
- Helps product and customer support teams focus on real pain points.  

---

## ðŸš€ Future Work  
- Extend to **multi-class classification** (positive / neutral / negative).  
- Experiment with **Linear SVM** and **transformer models (BERT)**.  
- Build a **Streamlit app** for real-time sentiment prediction. 
